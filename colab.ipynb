{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VBSWWY_DQJR",
        "outputId": "57484755-b436-4e71-afee-23cc8d6c7f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shareddrives/StellarSummarizers/the-stellar-summarizers-sp22\n"
          ]
        }
      ],
      "source": [
        "# first time setup only\n",
        "#!python ./fetch_dataset.py\n",
        "#!unzip ./frames.zip # only for first time setup\n",
        "\n",
        "# mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# move to the git repo\n",
        "%cd /content/drive/Shareddrives/StellarSummarizers/the-stellar-summarizers-sp22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "lzjXkqj2I8za",
        "outputId": "4a7d3f4a-0e65-4781-9784-756f97a0dec1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.12 ('acmai')' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'conda install -n acmai ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# from torchvision import transforms\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "#import the model for the CNN\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "class SumMeDataset(Dataset):\n",
        "    def __init__(self, annotations_filename, img_dir, transform=None, target_transform=None):\n",
        "\n",
        "        self.annotation_filename = annotations_filename\n",
        "        self.annotation = pd.read_csv(annotations_filename, header=0)\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "        self.video_name = img_dir.split('/')[-1]\n",
        "        self.frame_labels = self.annotation[self.annotation['video_name'] == self.video_name]['gt_score']\n",
        "\n",
        "        # not implemented yet\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, 'img_' + str(idx + 1).zfill(5) + '.jpg')\n",
        "        image = read_image(img_path)\n",
        "        label = self.frame_labels.iloc[idx]\n",
        "\n",
        "        # not implemented yet\n",
        "        if self.transform:\n",
        "            image = self.transform(ToPILImage()(image.to('cpu')))\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    annotations_filename = './frames/annotation.csv'\n",
        "    videos_root = './frames/Jumps'\n",
        "\n",
        "    # instantiating the dataset\n",
        "    dataset = SumMeDataset(annotations_filename, videos_root, transform=ToTensor())\n",
        "    print(len(dataset))\n",
        "\n",
        "    # data loader\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "    features, labels = next(iter(dataloader))\n",
        "    print(\"Data Loader:\")\n",
        "    print(f\"Feature batch shape: {features.size()}\")\n",
        "    print(f\"Labels batch shape: {labels.size()}\")\n",
        "\n",
        "    # get device for training\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using: {device.upper()}\")\n",
        "\n",
        "    # demo, shows the 1000th frame of the Bike_Polo video\n",
        "    sample = dataset[0]\n",
        "    plt.imshow(sample[0].permute(1, 2, 0))  # put channel data as last dimension\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yVRFGnTFkAI"
      },
      "outputs": [],
      "source": [
        "class new_resNext(torch.nn.Module):\n",
        "    def __init__(self, fc_size=2048, large = False, pretrained = True):\n",
        "        super(new_resNext,self).__init__()\n",
        "        if large:\n",
        "            self.model = models.resnext101_32x8d(pretrained=pretrained)\n",
        "        else:\n",
        "            self.model = models.resnext50_32x4d(pretrained=pretrained)\n",
        "        self.model.fc = torch.nn.Linear(fc_size,1)\n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "new_resNext = new_resNext()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0Omrc7KHVR4"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(dataloader)\n",
        "features, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "#imshow(torchvision.utils.make_grid(features))\n",
        "#print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqQlaBVKxo9N"
      },
      "outputs": [],
      "source": [
        "output_cnn = new_resNext(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwJptAwNxyaX"
      },
      "outputs": [],
      "source": [
        "features"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "b7326ebae4d92372e7dcd3b410e6455bc9a2fc2f07f36b12e8894e699dbc6c8d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('acmai')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
